{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ealrqqefbhliasbxhghh.supabase.co\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from supabase import create_client\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can access the variables\n",
    "my_var = os.getenv('SUPABASE_URL')\n",
    "print(my_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = os.getenv('SUPABASE_URL')\n",
    "key = os.getenv('API_KEY')\n",
    "supabase = create_client(url, key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'APIResponse[~_ReturnT]' object has no attribute 'status_code'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m response \u001b[38;5;241m=\u001b[39m supabase\u001b[38;5;241m.\u001b[39mtable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNewsSentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39minsert(data)\u001b[38;5;241m.\u001b[39mexecute()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Check the response\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m201\u001b[39m:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData inserted successfully:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32me:\\ML_projects\\github_repos\\git_repos_venv\\lib\\site-packages\\pydantic\\main.py:892\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[1;32m--> 892\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'APIResponse[~_ReturnT]' object has no attribute 'status_code'"
     ]
    }
   ],
   "source": [
    "# Example: Inserting a new record into the \"users\" table\n",
    "data = {\n",
    "    \"uuid\": 0,\n",
    "    \"headlines\": \"Taman\",\n",
    "    \"article_url\": \"india_today\",\n",
    "    \"category\" : \"bollywood\",\n",
    "    \"date_time\" : \"2024-12-18 20:55:00\"\n",
    "}\n",
    "\n",
    "response = supabase.table(\"NewsSentiment\").insert(data).execute()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APIResponse[~_ReturnT](data=[{'uuid': 0, 'headlines': 'Taman', 'article_url': 'india_today', 'category': 'bollywood', 'date_time': '2024-12-18T20:55:00'}], count=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "from queue import Queue\n",
    "from supabase import create_client\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Supabase client setup\n",
    "SUPABASE_URL = os.getenv('SUPABASE_URL')\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "supabase = create_client(SUPABASE_URL, API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for storing data\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "\n",
    "# Domains and their respective CSV files\n",
    "domain_files = {\n",
    "    \"sports\": \"sports_articles.csv\",\n",
    "    \"technology\": \"technology_articles.csv\",\n",
    "    \"lifestyle\": \"lifestyle_articles.csv\",\n",
    "    \"bollywood\": \"bollywood_articles.csv\",\n",
    "    \"business\": \"business_articles.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Save the queue\n",
    "def save_queue(queue, domain):\n",
    "    QUEUE_FILE = os.path.join(DATA_DIR, f\"{domain}_queue.pkl\")\n",
    "    with open(QUEUE_FILE, 'wb') as f:\n",
    "        pickle.dump(list(queue), f)  # Convert deque to list for saving\n",
    "    print(f\"Queue saved to {QUEUE_FILE}.\")\n",
    "\n",
    "# Load the queue\n",
    "def load_queue(domain):\n",
    "    QUEUE_FILE = os.path.join(DATA_DIR, f\"{domain}_queue.pkl\")\n",
    "    if os.path.exists(QUEUE_FILE):\n",
    "        with open(QUEUE_FILE, 'rb') as f:\n",
    "            return deque(pickle.load(f))  # Convert list back to deque\n",
    "    return deque()  # Return an empty deque if file doesn't exist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_database():\n",
    "    for domain, file_name in domain_files.items():\n",
    "        queue = load_queue(domain)\n",
    "        file_path = os.path.join(DATA_DIR, file_name)\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found for domain '{domain}': {file_name}\")\n",
    "            continue\n",
    "\n",
    "        # Read CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            record_uuid = row['UUID']\n",
    "\n",
    "\n",
    "            # Prepare data for Supabase\n",
    "            data = {\n",
    "                \"uuid\": record_uuid,\n",
    "                \"headlines\": row['Headline'],\n",
    "                \"article_url\": row['Link'],\n",
    "                \"category\": domain,\n",
    "                \"date_time\": row['DateTime'],\n",
    "                \"positive\" : row['Positive'],\n",
    "                \"negative\" : row['Negative']\n",
    "            }\n",
    "\n",
    "            # Insert into Supabase\n",
    "            try:\n",
    "                response = supabase.table(\"NewsSentiment\").insert(data).execute()\n",
    "                queue.append(record_uuid)  # Add record UUID to the queue\n",
    "            except Exception as e:\n",
    "                print(f\"Error inserting record UUID {record_uuid}: {e}\")\n",
    "\n",
    "        # Save the updated queue\n",
    "        save_queue(queue, domain)\n",
    "\n",
    "    print(\"Database update and queue management completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue saved to ../data\\sports_queue.pkl.\n",
      "Queue saved to ../data\\technology_queue.pkl.\n",
      "Queue saved to ../data\\lifestyle_queue.pkl.\n",
      "Queue saved to ../data\\bollywood_queue.pkl.\n",
      "Queue saved to ../data\\business_queue.pkl.\n",
      "Database update and queue management completed.\n"
     ]
    }
   ],
   "source": [
    "add_to_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "git_repos_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
